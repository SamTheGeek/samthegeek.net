---
title: "Google's ðŸš¨ RED ALERT ðŸš¨"
description: "If you pay attention to the news you know that Google is panicking over the recent research-level release of ChatGPT, one of Open AIâ€™s Large Language Models. But the roots of this crisis go back years to aâ€¦"
pubDate: "2023-01-10T19:36:00Z"
urlId: "2023/1/googles-red-alert"
updatedDate: 2023-01-12
likeCount: 1
commentCount: 0
excerptHtml: "<p>Google is in a panic about ChatGPT as a threat to its business. But were they <em>ever</em> really good enough to compete?</p>"
guid: "510ddd65e4b0837c157bd8f3:52603584e4b0c954af997030:63bd9420c22a440e068b05f9"
rssTitle: "Google's  RED ALERT"
rssDescription: "Google is in a panic about ChatGPT as a threat to its business. But were they ever really good enough to compete?"
rssContent: "<p>If you pay attention to the news you know that Google is panicking over the recent research-level release of ChatGPT, one of Open AIâ€™s Large Language Models. But the roots of this crisis go back years to a fundamental misunderstanding within Google about their core strengths.</p><p>Google has been the dominant search engine on the internet for a full generation â€” they <a href=\"https://www.nytimes.com/2006/12/23/technology/google-passes-yahoo-in-tally-of-visitors.html\">passed Yahoo in 2006</a>, reached 50% of search traffic in 2007, and have since become so ubiquitous that theyâ€™re a verb. Their product was, simply, better than anyone elseâ€™s: they crawled more of the web, ranked pages extremely accurately, and seemingly could find a result for any query to the point that thereâ€™s actually a game based around finding <a href=\"https://en.wikipedia.org/wiki/Googlewhack\">searches that only return exactly one result</a>. Their business model was simple, too: theyâ€™d place a single relevant ad or two at the top of the page, and people would occasionally click on them.</p><p>Then they forgot what their core product was. As more users became familiar with Google, they started to ask natural language questions rather than using keywords to get the best results. This style of searching, long the domain of librarians and <a href=\"https://en.wikipedia.org/wiki/Ask.com\">AskJeeves</a> is closer to how people are taught to interrogate the world around them. For folks who were used to only asking questions of other humans, this was entirely natural. Google was good enough at returning the right answer (most of the time) and so people learned to simply type their whole question into Google and look at the top two or three links.</p><p>Large Language Models are particularly well optimized for handling this particular way of interacting with humans. Theyâ€™re designed to parse human language by using a <em>massive</em> amount of existing text to discern the underlying meaning of a question â€” similar, in fact, to how humans use experience to understand one another. This is exactly what people think Google has been doing this whole time, except that they havenâ€™t been. Google added a â€˜<a href=\"https://support.google.com/knowledgepanel/answer/9163198?hl=en&amp;ref_topic=9164489\">Knowledge Panel</a>â€™ sidebar next to their search results, started generating their own summaries of search results, and inserted â€˜best guessâ€™ answers above the most relevant link to try and fulfill this need, but the primary results remain a ranked list of links.</p><p>For Google to be threatened by ChatGPT as a knowledge engine, their entry would <a href=\"https://www.vox.com/recode/22550555/google-search-knowledge-panels-serial-killer-misinformation-knowledge-graph\">have to be good</a>. OpenAI spent years comprehensively classifying the worldâ€™s information to make sure they have the right answer â€” and still gets it wrong sometimes. Google pulls from the highest-ranked pages with no evaluation as to the quality of information â€” with <a href=\"https://www.theatlantic.com/technology/archive/2019/09/googles-knowledge-panels-are-magnifying-disinformation/598474/\">predictable results</a>, notably uncritically <a href=\"https://globalextremism.org/post/google-s-knowledge-graph-is-rife-with-misinformation-and-an-easy-tool-for-online-radicalization/\">repeating conspiracy theories, antisemitic tropes, and other hate</a>. For people to trust a product like this, it needs to be perceived as 100% reliable. And it just isnâ€™t, itâ€™s too easy to fool. A single obviously-wrong result will lead people to <em>never</em> trusting it.</p> <iframe allowfullscreen src=\"//www.youtube.com/embed/YWdD206eSv0?wmode=opaque\" width=\"640\" height=\"480\"></iframe> <p>Itâ€™s like nobody watched Arthur as a kid or something</p> <p>Google has confused what theyâ€™re good at (page ranking) for being good at something else â€” they arenâ€™t, and have never been, a good knowledge engine. The risks to Googleâ€™s product are closer to home. Even average users (hi Dad!) are noticing that all of the content above-the-fold on a new search is now paid advertising, with the sidebar <em>also</em> mostly containing paid content. Meanwhile, a host of new competition has cropped up and the quality of Googleâ€™s ranking has declined as they fight an ever-escalating war against SEO tooling and spammy content. The only red alert I see is that the thing that makes Google all the money just isnâ€™t that good anymore. </p> <hr /> <p>For a really great take on some of the underlying problems in Googleâ€™s product culture, read Jackie Bavaroâ€™s <a href=\"https://jackiebavaro.substack.com/p/hot-take-google-has-a-company-strategy\">piece on their (lack of) product strategy</a>.</p><p>Thanks to my friend <a href=\"https://khanlou.com\">Soroush</a> for inspiring this post, <a href=\"https://pxlnv.com\">Nick Heer</a> for editing it, and various other folks for helping me refine my thoughts through <em>ahem</em> spirited debate.</p>"
---

If you pay attention to the news you know that Google is panicking over the recent research-level release of ChatGPT, one of Open AIâ€™s Large Language Models. But the roots of this crisis go back years to a fundamental misunderstanding within Google about their core strengths.

Google has been the dominant search engine on the internet for a full generation â€” they [passed Yahoo in 2006](https://www.nytimes.com/2006/12/23/technology/google-passes-yahoo-in-tally-of-visitors.html), reached 50% of search traffic in 2007, and have since become so ubiquitous that theyâ€™re a verb. Their product was, simply, better than anyone elseâ€™s: they crawled more of the web, ranked pages extremely accurately, and seemingly could find a result for any query to the point that thereâ€™s actually a game based around finding [searches that only return exactly one result](https://en.wikipedia.org/wiki/Googlewhack). Their business model was simple, too: theyâ€™d place a single relevant ad or two at the top of the page, and people would occasionally click on them.

Then they forgot what their core product was. As more users became familiar with Google, they started to ask natural language questions rather than using keywords to get the best results. This style of searching, long the domain of librarians and [AskJeeves](https://en.wikipedia.org/wiki/Ask.com) is closer to how people are taught to interrogate the world around them. For folks who were used to only asking questions of other humans, this was entirely natural. Google was good enough at returning the right answer (most of the time) and so people learned to simply type their whole question into Google and look at the top two or three links.

Large Language Models are particularly well optimized for handling this particular way of interacting with humans. Theyâ€™re designed to parse human language by using a *massive* amount of existing text to discern the underlying meaning of a question â€” similar, in fact, to how humans use experience to understand one another. This is exactly what people think Google has been doing this whole time, except that they havenâ€™t been. Google added a â€˜[Knowledge Panel](https://support.google.com/knowledgepanel/answer/9163198?hl=en&ref_topic=9164489)â€™ sidebar next to their search results, started generating their own summaries of search results, and inserted â€˜best guessâ€™ answers above the most relevant link to try and fulfill this need, but the primary results remain a ranked list of links.

For Google to be threatened by ChatGPT as a knowledge engine, their entry would [have to be good](https://www.vox.com/recode/22550555/google-search-knowledge-panels-serial-killer-misinformation-knowledge-graph). OpenAI spent years comprehensively classifying the worldâ€™s information to make sure they have the right answer â€” and still gets it wrong sometimes. Google pulls from the highest-ranked pages with no evaluation as to the quality of information â€” with [predictable results](https://www.theatlantic.com/technology/archive/2019/09/googles-knowledge-panels-are-magnifying-disinformation/598474/), notably uncritically [repeating conspiracy theories, antisemitic tropes, and other hate](https://globalextremism.org/post/google-s-knowledge-graph-is-rife-with-misinformation-and-an-easy-tool-for-online-radicalization/). For people to trust a product like this, it needs to be perceived as 100% reliable. And it just isnâ€™t, itâ€™s too easy to fool. A single obviously-wrong result will lead people to *never* trusting it.

<iframe width="640" height="360" src="https://www.youtube.com/embed/YWdD206eSv0" loading="lazy" allowfullscreen></iframe>

Itâ€™s like nobody watched Arthur as a kid or something

Google has confused what theyâ€™re good at (page ranking) for being good at something else â€” they arenâ€™t, and have never been, a good knowledge engine. The risks to Googleâ€™s product are closer to home. Even average users (hi Dad!) are noticing that all of the content above-the-fold on a new search is now paid advertising, with the sidebar *also* mostly containing paid content. Meanwhile, a host of new competition has cropped up and the quality of Googleâ€™s ranking has declined as they fight an ever-escalating war against SEO tooling and spammy content. The only red alert I see is that the thing that makes Google all the money just isnâ€™t that good anymore.

---

For a really great take on some of the underlying problems in Googleâ€™s product culture, read Jackie Bavaroâ€™s [piece on their (lack of) product strategy](https://jackiebavaro.substack.com/p/hot-take-google-has-a-company-strategy).

Thanks to my friend [Soroush](https://khanlou.com) for inspiring this post, [Nick Heer](https://pxlnv.com) for editing it, and various other folks for helping me refine my thoughts through *ahem* spirited debate.
